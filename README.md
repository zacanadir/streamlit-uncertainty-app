# 🧠 Uncertainty Explorer

This interactive Streamlit app lets you explore **model uncertainty** in predictions — blending classic machine learning with deep learning techniques like **Monte Carlo Dropout** for uncertainty estimation.

Built with the goal of making predictive models more transparent, this app shows both static and uncertainty-aware predictions and helps you interpret **what the model is confident about — and where it's not**.

---

## 🚀 What You Can Do

- 🔍 Compare predictions from a standard model (e.g. Random Forest) vs a neural network using **MC Dropout**
- 📈 Visualize predicted probabilities and uncertainty intervals
- 🎯 Understand which features drive predictions using **SHAP values**
- 🤖 Experiment with different inputs and observe model behavior
- 📊 Learn how overfitting and uncertainty relate to each other

---

## 🛠 Tech Stack

- [Streamlit](https://streamlit.io/) – for the interactive UI
- [scikit-learn](https://scikit-learn.org/) – for classical ML models
- [TensorFlow / Keras](https://www.tensorflow.org/) – for the MC Dropout neural network
- [SHAP](https://github.com/slundberg/shap) – for model interpretability
- [Plotly](https://plotly.com/python/) – for interactive graphs

---

## 📚 Why It Matters

In real-world applications, it's not just about what the model predicts — it's about how **confident** the model is.

By combining MC Dropout with SHAP values, this app demonstrates how to measure and visualize **epistemic uncertainty**, providing deeper insights for decision-making in fields like:

- Medical diagnosis
- Financial forecasting
- Risk management
- Any high-stakes predictive system

---

## 🔗 Try It Live

👉 [Click here to launch the app](https://app-uncertainty-app-2vzxvtfqwkxgbaesjfwfyc.streamlit.app)

---

## 💬 Let's Connect!

Made with ❤️ by Zakaria Nadir

📫 zacanadir@gmail.com
