# ğŸ§  Uncertainty Explorer

This interactive Streamlit app lets you explore **model uncertainty** in predictions â€” blending classic machine learning with deep learning techniques like **Monte Carlo Dropout** for uncertainty estimation.

Built with the goal of making predictive models more transparent, this app shows both static and uncertainty-aware predictions and helps you interpret **what the model is confident about â€” and where it's not**.

---

## ğŸš€ What You Can Do

- ğŸ” Compare predictions from a standard model (e.g. Random Forest) vs a neural network using **MC Dropout**
- ğŸ“ˆ Visualize predicted probabilities and uncertainty intervals
- ğŸ¯ Understand which features drive predictions using **SHAP values**
- ğŸ¤– Experiment with different inputs and observe model behavior
- ğŸ“Š Learn how overfitting and uncertainty relate to each other

---

## ğŸ›  Tech Stack

- [Streamlit](https://streamlit.io/) â€“ for the interactive UI
- [scikit-learn](https://scikit-learn.org/) â€“ for classical ML models
- [TensorFlow / Keras](https://www.tensorflow.org/) â€“ for the MC Dropout neural network
- [SHAP](https://github.com/slundberg/shap) â€“ for model interpretability
- [Plotly](https://plotly.com/python/) â€“ for interactive graphs

---

## ğŸ“š Why It Matters

In real-world applications, it's not just about what the model predicts â€” it's about how **confident** the model is.

By combining MC Dropout with SHAP values, this app demonstrates how to measure and visualize **epistemic uncertainty**, providing deeper insights for decision-making in fields like:

- Medical diagnosis
- Financial forecasting
- Risk management
- Any high-stakes predictive system

---

## ğŸ”— Try It Live

ğŸ‘‰ [Click here to launch the app](https://app-uncertainty-app-2vzxvtfqwkxgbaesjfwfyc.streamlit.app)

---

## ğŸ’¬ Let's Connect!

Made with â¤ï¸ by Zakaria Nadir

ğŸ“« zacanadir@gmail.com
